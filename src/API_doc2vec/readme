v0.0.1
１．使用word2vec之后的词向量库，作为整体词典；
２．多个词向量与词典进行匹配，并计算距离作为特征，生成句向量；
缺点一：匹配量太大，性能损耗；
缺点二：句向量维度太高，需做降维；
实验时，全数据匹配，2000样本训练，数据交叉验证95%；5000样本，90%;（已考虑句向量排重）

v0.0.2
１．使用word2vec之后的词向量库，作为整体词典，同时引入hamming码；
２．多个词向量获取hamming码与词典hamming码进行匹配，未匹配到的维置零，匹配到的维进行距离计算，并寻找最大值作为特征，生成句向量；
优点一：匹配量小，相比v0.0.1；
缺点一：句向量维度还是太高，需做降维；
缺点二：句向量稀疏度高，信息丢失大；
实验时，1000维数据匹配，2000样本训练，数据交叉验证72%；（已考虑句向量排重）

v0.0.3
１．使用word2vec之后的词向量库，作为整体词典；
２．多个词向量组合为句向量时，直接进行加权累加／求最大；
优点一：匹配量小，相比v0.0.1；
优点二：句向量维度与词向量维度一致，可做降维也可不做；
缺点一：句向量语义破坏；
实验时，全数据匹配，2000样本训练，数据交叉验证93%；5000样本，92%;（已考虑句向量排重）

